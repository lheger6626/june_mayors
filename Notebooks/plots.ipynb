{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "import os\n",
    "import numpy as np\n",
    "from june.records import RecordReader\n",
    "from june.hdf5_savers import generate_world_from_hdf5\n",
    "from pandas.core.groupby.groupby import DataError\n",
    "import matplotlib.dates as mdates\n",
    "import datetime\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_format_sim_infs(path, start_date=\"2020-10-01\", end_date=\"2020-12-25\"):\n",
    "    print(f\"loading {path}\")\n",
    "    try:\n",
    "        rec = RecordReader(path) \n",
    "        df = rec.get_table_with_extras(\"infections\", \"infected_ids\")\n",
    "    except DataError:\n",
    "        print(\"sim has not started yet. Discarded.\")\n",
    "        return None\n",
    "    if rec.get_world_summary().index.max() < pd.to_datetime(end_date):\n",
    "        print(f\"run {path} not done yet. Discarded\")\n",
    "        return None\n",
    "    \n",
    "    a = df.loc[df.primary_activity_type==\"school\",:].groupby(\"timestamp\").size()\n",
    "    b = df.loc[df.primary_activity_type!=\"school\",:].groupby(\"timestamp\").size()\n",
    "    sim_data = pd.concat([a,b], keys=[\"school\", \"other\"], axis=1)\n",
    "    return sim_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_format_sim_hosps(path, start_date=\"2020-10-01\", end_date=\"2020-12-25\"):\n",
    "    print(f\"loading {path}\")\n",
    "    try:\n",
    "        rec = RecordReader(path) \n",
    "        df = rec.get_table_with_extras(\"hospital_admissions\", \"patient_ids\")\n",
    "    except DataError:\n",
    "        print(\"sim has not started yet. Discarded.\")\n",
    "        return None\n",
    "    if rec.get_world_summary().index.max() < pd.to_datetime(end_date):\n",
    "        print(f\"run {path} not done yet. Discarded\")\n",
    "        return None\n",
    "    \n",
    "    a = df.loc[df.primary_activity_type==\"school\",:].groupby(\"timestamp\").size()\n",
    "    b = df.loc[df.primary_activity_type!=\"school\",:].groupby(\"timestamp\").size()\n",
    "    sim_data = pd.concat([a,b], keys=[\"school\", \"other\"], axis=1)\n",
    "    return sim_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mount = \"/home/lheger/JUNE_germany_private/parameter_studies/results/\" # path to your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load q68 runs schools open\n",
    "q_68_i_so = pd.concat([load_and_format_sim_infs(mount + \"q68_schools_open/\" + file, \n",
    "                                                end_date=\"2021-03-19\") \\\n",
    "                       for file in os.listdir(mount + \"q68_schools_open/\")\n",
    "                      ], \n",
    "                      keys=[file for file in os.listdir(mount + \"q68_schools_open/\")]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load q68 runs\n",
    "q_68_i = pd.concat([load_and_format_sim_infs(mount + \"q68_complete_second_wave/\" + file, \n",
    "                                           end_date=\"2021-03-19\") \\\n",
    "                  for file in os.listdir(mount + \"q68_complete_second_wave/\")\n",
    "                 ], \n",
    "                 keys=[file for file in os.listdir(mount + \"q68_complete_second_wave/\")]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load q68 runs schools open\n",
    "q_68_h_so = pd.concat([load_and_format_sim_hosps(mount + \"q68_schools_open/\" + file, \n",
    "                                                end_date=\"2021-03-19\") \\\n",
    "                       for file in os.listdir(mount + \"q68_schools_open/\")\n",
    "                      ], \n",
    "                      keys=[file for file in os.listdir(mount + \"q68_schools_open/\")]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load q68 runs schools open\n",
    "q_68_h = pd.concat([load_and_format_sim_hosps(mount + \"q68_complete_second_wave/\" + file, \n",
    "                                                end_date=\"2021-03-19\") \\\n",
    "                       for file in os.listdir(mount + \"q68_complete_second_wave/\")\n",
    "                      ], \n",
    "                      keys=[file for file in os.listdir(mount + \"q68_complete_second_wave/\")]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load q68 runs schools open\n",
    "q_68_i_np = pd.concat([load_and_format_sim_infs(mount + \"q68_no_policies/\" + file, \n",
    "                                                end_date=\"2021-03-19\") \\\n",
    "                       for file in os.listdir(mount + \"q68_no_policies/\")\n",
    "                      ], \n",
    "                      keys=[file for file in os.listdir(mount + \"q68_no_policies/\")]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load q68 runs schools open\n",
    "q_68_h_np = pd.concat([load_and_format_sim_hosps(mount + \"q68_no_policies/\" + file, \n",
    "                                                end_date=\"2021-03-19\") \\\n",
    "                       for file in os.listdir(mount + \"q68_no_policies/\")\n",
    "                      ], \n",
    "                      keys=[file for file in os.listdir(mount + \"q68_no_policies/\")]\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# properly named configs from q68_schools_open\n",
    "named_configs = dict()\n",
    "p = mount + \"q68_schools_open/\"\n",
    "for run in os.listdir(p):\n",
    "    with open(f\"{p}{run}/config.yaml\") as f:\n",
    "        ff = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    try:\n",
    "        named_configs[run] = ff[\"interaction\"][\"betas\"]\n",
    "    except KeyError:\n",
    "        print(f\"{run} does not contain proper configs, dismiss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = dict()\n",
    "p = mount + \"q68_complete_second_wave/\"\n",
    "for file in os.listdir(p):\n",
    "    with open(f\"{p}{file}/config.yaml\") as f:\n",
    "        ff = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        try:\n",
    "            betas = ff[\"interaction\"][\"betas\"]\n",
    "            for config in named_configs:\n",
    "                if betas == named_configs[config]:\n",
    "                    match[config] = file\n",
    "        except KeyError:\n",
    "            print(f\"{file} does not contain proper configs, dismiss\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_68_i_so = q_68_i_so.loc[list(match.keys())]\n",
    "q_68_h_so = q_68_h_so.loc[list(match.keys())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_68_i = q_68_i.rename(index={v:k for k,v in match.items()}, level=0)\n",
    "q_68_h = q_68_h.rename(index={v:k for k,v in match.items()}, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_68_i = q_68_i.sort_index()\n",
    "q_68_i_so = q_68_i_so.sort_index()\n",
    "\n",
    "q_68_h = q_68_h.sort_index()\n",
    "q_68_h_so = q_68_h_so.sort_index()\n",
    "\n",
    "q_68_i_np = q_68_i_np.sort_index()\n",
    "q_68_h_np = q_68_i_np.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_68_h = q_68_h.fillna(0)\n",
    "q_68_h_so = q_68_h_so.fillna(0)\n",
    "\n",
    "q_68_i_np = q_68_i_np.fillna(0)\n",
    "q_68_h_np = q_68_i_np.fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_68_i_norm_fac = q_68_i.groupby(level=0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "err = q_68_h.groupby(\"timestamp\").std()\n",
    "err_so = q_68_h_so.groupby(\"timestamp\").std()\n",
    "err_np = q_68_h_np.groupby(\"timestamp\").std()\n",
    "\n",
    "y = q_68_h.groupby(level=1).mean()\n",
    "y_np = q_68_h_np.groupby(level=1).mean()\n",
    "\n",
    "\n",
    "q_68_h.groupby(level=1).mean().loc[:,\"other\"].rolling(7).mean().plot(ax=ax, \n",
    "                                                                     color=\"#1f77b4\", \n",
    "                                                                     label=\"state policies\", \n",
    "                                                                     lw=2)\n",
    "\n",
    "q_68_h_np.groupby(level=1).mean().loc[:,\"other\"].rolling(7).mean().plot(ax=ax, \n",
    "                                                                        color=\"#ff7f0e\", \n",
    "                                                                        label=\"no state policies\", \n",
    "                                                                        lw=2)\n",
    "\n",
    "ax.fill_between(y.loc[:,\"other\"].rolling(7).mean().index, \n",
    "                    y.loc[:,\"other\"].rolling(7).mean() - err.loc[:,\"other\"].rolling(7).mean(), \n",
    "                    y.loc[:,\"other\"].rolling(7).mean() + err.loc[:,\"other\"].rolling(7).mean(), \n",
    "                    alpha=0.2)\n",
    "\n",
    "ax.fill_between(y_np.loc[:,\"other\"].rolling(7).mean().index, \n",
    "                    y_np.loc[:,\"other\"].rolling(7).mean() - err_np.loc[:,\"other\"].rolling(7).mean(), \n",
    "                    y_np.loc[:,\"other\"].rolling(7).mean() + err_np.loc[:,\"other\"].rolling(7).mean(), \n",
    "                    alpha=0.2)\n",
    "\n",
    "\n",
    "ax.legend(fontsize=10, loc=\"upper right\")\n",
    "\n",
    "ax.set_ylabel(\"hospitalisations\", fontsize=10)\n",
    "ax.set_xlabel(\"\")\n",
    "\n",
    "\n",
    "ax.yaxis.set_tick_params(labelsize=10)\n",
    "\n",
    "ax.yaxis.set_tick_params(labelsize=10)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "err = q_68_h.groupby(\"timestamp\").std()\n",
    "err_so = q_68_h_so.groupby(\"timestamp\").std()\n",
    "err_np = q_68_h_np.groupby(\"timestamp\").std()\n",
    "\n",
    "y = q_68_h.groupby(level=1).mean()\n",
    "y_so = q_68_h_so.groupby(level=1).mean()\n",
    "\n",
    "\n",
    "q_68_h.groupby(level=1).mean().loc[:,\"other\"].rolling(7).mean().plot(ax=ax, \n",
    "                                                                     color=\"#1f77b4\", \n",
    "                                                                     label=\"state policies\", \n",
    "                                                                     lw=2)\n",
    "\n",
    "q_68_h_so.groupby(level=1).mean().loc[:,\"other\"].rolling(7).mean().plot(ax=ax, \n",
    "                                                                        color=\"#ff7f0e\", \n",
    "                                                                        label=\"no school closures\", \n",
    "                                                                        lw=2)\n",
    "\n",
    "ax.fill_between(y.loc[:,\"other\"].rolling(7).mean().index, \n",
    "                    y.loc[:,\"other\"].rolling(7).mean() - err.loc[:,\"other\"].rolling(7).mean(), \n",
    "                    y.loc[:,\"other\"].rolling(7).mean() + err.loc[:,\"other\"].rolling(7).mean(), \n",
    "                    alpha=0.2)\n",
    "\n",
    "ax.fill_between(y_so.loc[:,\"other\"].rolling(7).mean().index, \n",
    "                    y_so.loc[:,\"other\"].rolling(7).mean() - err_so.loc[:,\"other\"].rolling(7).mean(), \n",
    "                    y_so.loc[:,\"other\"].rolling(7).mean() + err_so.loc[:,\"other\"].rolling(7).mean(), \n",
    "                    alpha=0.2)\n",
    "\n",
    "\n",
    "ax.legend(fontsize=10, loc=\"upper left\")\n",
    "\n",
    "ax.set_ylabel(\"hospitalisations\", fontsize=10)\n",
    "ax.set_xlabel(\"\")\n",
    "\n",
    "\n",
    "ax.yaxis.set_tick_params(labelsize=10)\n",
    "\n",
    "ax.yaxis.set_tick_params(labelsize=10)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make plots that require infection per super area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_format_sim_infs_per_super_area(path, start_date=\"2020-10-01\", end_date=\"2020-12-25\"):\n",
    "    print(f\"loading {path}\")\n",
    "    def preprocess_simdata(df):\n",
    "        return (df\n",
    "                .groupby([\"timestamp\",\"name_super_area\"])\n",
    "                .size()\n",
    "                #.sum(level=1)\n",
    "               )\n",
    "    try:\n",
    "        df = RecordReader(path).get_table_with_extras(\"infections\", \"infected_ids\")\n",
    "    except DataError:\n",
    "        print(\"sim has not started yet. Discarded.\")\n",
    "        return None\n",
    "    if df.timestamp.max() < pd.to_datetime(end_date):\n",
    "        print(f\"run {path} not done yet. Discarded\")\n",
    "        return None\n",
    "    return preprocess_simdata(df)\n",
    "\n",
    "def load_and_format_target_infs_per_super_area():    \n",
    "    targets = pd.read_csv(mount + \"/home/lheger/june_fitting/data/infektionen.csv\")\n",
    "    targets = (targets\n",
    "               .loc[targets.bundesland==\"Rheinland-Pfalz\"]\n",
    "               .drop([\"_id\", \"ags5\", \"ags2\", \"bundesland\"], axis=1))\n",
    "\n",
    "    targets = (targets\n",
    "               .rename(columns={col:col[1:] for col in targets.columns if col[0]==\"d\"})\n",
    "               .loc[targets.loc[:,\"variable\"].str.contains(\"kr_inf_a\") \n",
    "                    & ~targets.loc[:,\"variable\"].str.contains(\"kr_inf_aktiv\"),:]\n",
    "              )\n",
    "    targets = (targets\n",
    "               .groupby([\"kreis\", \"variable\"])\n",
    "               .sum()\n",
    "               .T)\n",
    "\n",
    "    targets = (targets\n",
    "               .reindex(pd.to_datetime(targets.index))\n",
    "              )\n",
    "\n",
    "    #targets = targets.rename(columns={col:rename_agegroup_columns(col) for col in targets.columns.droplevel()}, level=1)\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_most_similar_super_area_name(old_super_area_name, \n",
    "                                      new_super_area_names\n",
    "                                     ):\n",
    "    if old_super_area_name not in new_super_area_names:\n",
    "        similarity_score = 0\n",
    "        new_super_area_name = None\n",
    "        for candidate in new_super_area_names:\n",
    "            candidate_similarity_score = SequenceMatcher(None, old_super_area_name, candidate).ratio()\n",
    "            if candidate_similarity_score > similarity_score:\n",
    "                similarity_score = candidate_similarity_score\n",
    "                new_super_area_name = candidate\n",
    "    else:\n",
    "        new_super_area_name = old_super_area_name\n",
    "    \n",
    "    if new_super_area_name is None:\n",
    "        raise ValueError(\"the new super area name cannot be None\")\n",
    "    return new_super_area_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "world = generate_world_from_hdf5(\"../data/world_rlp.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the names of the super areas since we need to match the codes to the names to compare sim to real data\n",
    "df = pd.read_csv(\"/home/lheger/JUNE_germany_private/data/geography/super_area_coordinates.csv\")\n",
    "df = df.drop([\"latitude\", \"longitude\"], axis=1)\n",
    "super_area_name_lookup = dict(zip(df.super_area, df.super_area_name))\n",
    "# fixing a bug in the data. the kreis kaiserslautern and the kreisfreie stadt kaiserslautern\n",
    "# carry the same name. the kreisfreie stadt should be stadt kaiserslautern\n",
    "super_area_name_lookup[\"D07312\"] = \"Stadt Kaiserslautern\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_per_sa_lookup = {super_area_name_lookup[sa.name]:len(sa.people) for sa in world.super_areas}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q68_i_sa = pd.concat([load_and_format_sim_infs_per_super_area(mount + \"q68_complete_second_wave/\" + file, \n",
    "                                                             end_date=\"2021-03-19\") \\\n",
    "                     for file in os.listdir(mount + \"q68_complete_second_wave/\")\n",
    "                    ], \n",
    "                    keys=[file for file in os.listdir(mount + \"q68_complete_second_wave/\")]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set super area codes to kreis names and name levels of index\n",
    "q68_i_sa = q68_i_sa.rename(index={ags:super_area_name_lookup[ags] for ags in q68_i_sa.index.levels[2]}, level=2)\n",
    "q68_i_sa = q68_i_sa.reindex(q68_i_sa.index.set_names([\"run\", \"timestamp\", \"name_super_area\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load targets and sum over age groups\n",
    "targets = load_and_format_target_infs_per_super_area()\n",
    "targets.index.name = \"timestamp\"\n",
    "targets = targets.unstack().groupby([\"kreis\", \"timestamp\"]).sum()\n",
    "\n",
    "# rename Kreise in targets to match june naming convention\n",
    "new_idx = {old_idx:find_most_similar_super_area_name(old_idx, \n",
    "                                                     list(pop_per_sa_lookup.keys()))\n",
    "           for old_idx in targets.index.levels[0]}\n",
    "targets = targets.rename(index=new_idx, level=0)\n",
    "targets = targets.sort_index()\n",
    "\n",
    "# select total infections per kreis at eval date\n",
    "target_infs_per_sa = targets.groupby(\"kreis\").cumsum().loc[:,pd.to_datetime(\"2021-03-19\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yerr = target_infs_per_sa*0.05 # schott"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xerr = (q68_i_sa\n",
    "        .groupby([\"timestamp\",\"name_super_area\"])\n",
    "        .std()\n",
    "        .groupby(\"name_super_area\")\n",
    "        .apply(lambda x:np.sqrt(np.sum(x**2)))\n",
    "       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scatterplot(sims, target):\n",
    "    yerr = target*0.05\n",
    "    xerr = (sims\n",
    "        .groupby([\"timestamp\",\"name_super_area\"])\n",
    "        .std()\n",
    "        .groupby(\"name_super_area\")\n",
    "        .apply(lambda x:np.sqrt(np.sum(x**2)))\n",
    "       )\n",
    "    \n",
    "    x = sims.groupby([\"timestamp\",\"name_super_area\"]).mean().groupby(\"name_super_area\").sum().to_numpy()\n",
    "    y = target.to_numpy()\n",
    "    #plt.scatter(x,y)\n",
    "    plt.errorbar(x,y,yerr=yerr,xerr=xerr,fmt='o',capsize=3, capthick=2, elinewidth=1,markersize=5)\n",
    "    plt.ylabel(\"data\")\n",
    "    plt.xlabel(\"simulation\")\n",
    "    plt.tight_layout()\n",
    "    return plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_corr(sims,targets):\n",
    "    a = sims.groupby([\"run\",\"name_super_area\"]).sum().unstack().to_numpy()\n",
    "    b = targets.to_numpy()\n",
    "    corrs = []\n",
    "    for i in range(22):\n",
    "        corrs.append(np.corrcoef(a[i,:],b)[0,1])\n",
    "    return np.array(corrs).mean(),np.array(corrs).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = make_scatterplot(q68_i_sa, target_infs_per_sa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_targets = dict()\n",
    "norm_sim = dict()\n",
    "for k in pop_per_sa_lookup:\n",
    "    norm_fac = pop_per_sa_lookup[k]/10000\n",
    "    norm_targets[k] = target_infs_per_sa.loc[k]/norm_fac\n",
    "    norm_sim[k] = q68_i_sa.loc[:,:,k]/norm_fac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q68_i_sa_norm = pd.DataFrame(norm_sim).stack()\n",
    "idx = q68_i_sa_norm.index\n",
    "q68_i_sa_norm = q68_i_sa_norm.reindex(idx.set_names(\"name_super_area\",level=-1))\n",
    "targets_i_sa_norm = pd.Series(norm_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = make_scatterplot(q68_i_sa_norm,targets_i_sa_norm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
